# -*- coding: utf-8 -*-
"""
Created on Thu Oct 30 22:02:53 2025

@author: 20152
"""

# -*- coding: utf-8 -*-
import json, os
from pathlib import Path
import numpy as np
import faiss
import requests
import streamlit as st
from sentence_transformers import SentenceTransformer

# ==== è·¯å¾„ï¼ˆæŒ‰ä½ çš„ç»å¯¹è·¯å¾„ï¼‰====
PROJECT_ROOT = Path("D:/Chatbot/RAG")
INDEX_DIR = PROJECT_ROOT / "data/index"
FAISS_PATH = INDEX_DIR / "corpus.faiss"
META_PATH  = INDEX_DIR / "metadata.json"
OLLAMA_URL = "http://localhost:11434"
MODEL_NAME = "cniongolo/biomistral"  # ä½ æœ¬æœºçš„æ¨¡å‹

# ==== ç¼“å­˜åŠ è½½ ====
@st.cache_resource
def load_index_and_meta():
    if not FAISS_PATH.exists() or not META_PATH.exists():
        raise FileNotFoundError(
            f"ç´¢å¼•ç¼ºå¤±ï¼š\n{FAISS_PATH}\n{META_PATH}\nè¯·å…ˆè¿è¡Œ build_index.py ç”Ÿæˆç´¢å¼•ã€‚"
        )
    index = faiss.read_index(str(FAISS_PATH))
    with open(META_PATH, "r", encoding="utf-8") as f:
        meta = json.load(f)
    docs  = np.array(meta["docs"], dtype=object)
    metas = meta["metas"]
    return index, docs, metas

@st.cache_resource
def get_embedder():
    return SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

def embed_texts(texts):
    model = get_embedder()
    return model.encode(texts, normalize_embeddings=True, convert_to_numpy=True, show_progress_bar=False)

def categories_from_meta(metas):
    cats = [m.get("category") for m in metas if m.get("category")]
    cats = sorted(set(cats))
    return ["(å…¨éƒ¨)"] + cats if cats else ["(å…¨éƒ¨)"]

def retrieve(question, k=6, category=None):
    index, docs, metas = load_index_and_meta()
    qv = embed_texts([question])
    D, I = index.search(qv, max(k*4, k))

    def pick(Irow, catwant):
        picked = []
        for i in Irow:
            m = metas[i]
            cat = m.get("category")
            if catwant and catwant != "(å…¨éƒ¨)" and cat != catwant:
                continue
            picked.append((i, m, docs[i]))
            if len(picked) >= k: break
        return picked

    cand = pick(I[0], category)
    if not cand and category and category != "(å…¨éƒ¨)":
        cand = pick(I[0], None)  # å›é€€åˆ°å…¨åº“

    ctx_lines = []
    for i, m, t in cand:
        tag = f"[{m.get('category')}/{m.get('source')}]"
        ctx_lines.append(f"{tag} {t}")
    return "\n".join(ctx_lines), cand

def build_prompt(question, context):
    system = (
        "Tu es un assistant mÃ©dical spÃ©cialisÃ© en imagerie (TEP/IRM/TDM).\n"
        "RÃ‰PONDS UNIQUEMENT Ã€ PARTIR DU CONTEXTE fourni ci-dessous.\n"
        "Ne rÃ©pÃ¨te pas le contexte ni les consignes. Si l'information manque, rÃ©ponds : Â« Je ne sais pas Â».\n"
        "Structure impÃ©rativement la rÃ©ponse en 4 parties : Indication, Technique, RÃ©sultats, Conclusion.\n"
        "Ne change pas les termes de la question. Cite briÃ¨vement les sources entre []."
    )
    return f"{system}\n\n### CONTEXTE\n{context}\n\n### QUESTION\n{question}\n\n### RÃ‰PONSE ATTENDUE (FR)\n"

def ask_ollama(prompt, model=MODEL_NAME, temperature=0.1, max_tokens=700, host=OLLAMA_URL):
    try:
        r = requests.post(
            f"{host}/api/generate",
            json={"model": model, "prompt": prompt, "stream": False,
                  "options": {"temperature": temperature, "num_predict": max_tokens}},
            timeout=120
        )
        if r.status_code != 200:
            return f"[é”™è¯¯] Ollama HTTP {r.status_code}ï¼š{r.text[:200]}"
        text = (r.json().get("response") or "").strip()
        return text if text else "Je ne sais pas."
    except requests.exceptions.RequestException as e:
        return f"[é”™è¯¯] æ— æ³•è¿æ¥åˆ° Ollamaï¼ˆ{host}ï¼‰ï¼š{e}"

def rag_answer(question, k=6, category=None):
    context, hits = retrieve(question, k=k, category=category)
    if not context or len(hits) == 0:
        return "Je ne sais pas. (Contexte insuffisant ou hors du corpus.)", context
    prompt = build_prompt(question, context)
    ans = ask_ollama(prompt)
    if ans.strip().startswith("Tu es un assistant") or ("Indication" not in ans and "Conclusion" not in ans):
        ans = "Je ne sais pas. (La rÃ©ponse n'est pas basÃ©e sur le contexte.)"
    return ans, context

# ==== UI ====
st.set_page_config(page_title="RAG Radiologie (Local)", layout="wide")
st.title("ğŸ©» RAG Radiologie â€” Local (Ollama + BioMistral)")

# ä¾§æ å‚æ•°
with st.sidebar:
    st.markdown("### âš™ï¸ å‚æ•°")
    try:
        _, _, metas = load_index_and_meta()
        cat_options = categories_from_meta(metas)
    except Exception as e:
        cat_options = ["(å…¨éƒ¨)"]
        st.error(str(e))

    category = st.selectbox("ç±»åˆ«ï¼ˆå­æ–‡ä»¶å¤¹ï¼‰", cat_options, index=0)
    k = st.slider("æ£€ç´¢æ¡æ•° k", min_value=4, max_value=12, value=6, step=1)
    temp = st.slider("Temperature", 0.0, 1.0, 0.1, 0.05)
    max_new = st.slider("Max tokens", 128, 1024, 700, 64)

question = st.text_area("â“ è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼ˆæ³•è¯­æ›´ä½³ï¼‰", height=100,
                        placeholder="Ex: Quelle est la structure dâ€™un compte rendu TEP-IRM FDOPA ?")
col1, col2 = st.columns([1,1])
with col1:
    ask = st.button("ğŸ” æé—®")
with col2:
    demo = st.button("âœ¨ ç¤ºä¾‹é—®é¢˜")

if demo and not question.strip():
    question = "Que signifie une hypofixation putaminale bilatÃ©rale ?"
    st.session_state["question"] = question

if ask or (demo and question):
    with st.spinner("æ£€ç´¢ä¸ç”Ÿæˆä¸­â€¦"):
        ans, ctx = rag_answer(question.strip(), k=k, category=category)
    st.markdown("### ğŸ§  ç­”æ¡ˆ")
    st.write(ans)

    with st.expander("ğŸ” æœ¬æ¬¡ä½¿ç”¨çš„ä¸Šä¸‹æ–‡ï¼ˆæ¥æºç‰‡æ®µï¼‰"):
        st.code(ctx or "(æ— )", language="markdown")

st.caption("æœ¬åœ°æ¨ç† Â· æ¨¡å‹ï¼š%s Â· ç´¢å¼•ï¼š%s" % (MODEL_NAME, FAISS_PATH))
